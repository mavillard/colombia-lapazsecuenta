{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TÃ³picos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-06 15:56:13,234 : INFO : 'pattern' package not found; tag filters are not available for English\n"
     ]
    }
   ],
   "source": [
    ">>> from gensim import corpora\n",
    ">>>\n",
    ">>> documents = [\"Human machine interface for lab abc computer applications\",\n",
    ">>>              \"A survey of user opinion of computer system response time\",\n",
    ">>>              \"The EPS user interface management system\",\n",
    ">>>              \"System and human system engineering testing of EPS\",\n",
    ">>>              \"Relation of user perceived response time to error measurement\",\n",
    ">>>              \"The generation of random binary unordered trees\",\n",
    ">>>              \"The intersection graph of paths in trees\",\n",
    ">>>              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    ">>>              \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['human', 'interface', 'computer'],\n",
      " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
      " ['eps', 'user', 'interface', 'system'],\n",
      " ['system', 'human', 'system', 'eps'],\n",
      " ['user', 'response', 'time'],\n",
      " ['trees'],\n",
      " ['graph', 'trees'],\n",
      " ['graph', 'minors', 'trees'],\n",
      " ['graph', 'minors', 'survey']]\n"
     ]
    }
   ],
   "source": [
    ">>> # remove common words and tokenize\n",
    ">>> stoplist = set('for a of the and to in'.split())\n",
    ">>> texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    ">>>          for document in documents]\n",
    ">>>\n",
    ">>> # remove words that appear only once\n",
    ">>> from collections import defaultdict\n",
    ">>> frequency = defaultdict(int)\n",
    ">>> for text in texts:\n",
    ">>>     for token in text:\n",
    ">>>         frequency[token] += 1\n",
    ">>>\n",
    ">>> texts = [[token for token in text if frequency[token] > 1]\n",
    ">>>          for text in texts]\n",
    ">>>\n",
    ">>> from pprint import pprint  # pretty-printer\n",
    ">>> pprint(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-06 15:58:30,805 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-08-06 15:58:30,809 : INFO : built Dictionary(12 unique tokens: ['trees', 'graph', 'survey', 'response', 'interface']...) from 9 documents (total 29 corpus positions)\n",
      "2018-08-06 15:58:30,811 : INFO : saving Dictionary object under /tmp/deerwester.dict, separately None\n",
      "2018-08-06 15:58:30,813 : INFO : saved /tmp/deerwester.dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: ['trees', 'graph', 'survey', 'response', 'interface']...)\n"
     ]
    }
   ],
   "source": [
    ">>> dictionary = corpora.Dictionary(texts)\n",
    ">>> dictionary.save('/tmp/deerwester.dict')  # store the dictionary, for future reference\n",
    ">>> print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'trees': 9, 'graph': 10, 'survey': 4, 'response': 3, 'interface': 2, 'user': 7, 'time': 6, 'human': 1, 'minors': 11, 'system': 5, 'computer': 0, 'eps': 8}\n"
     ]
    }
   ],
   "source": [
    ">>> print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    ">>> new_doc = \"Human computer interaction\"\n",
    ">>> new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    ">>> print(new_vec)  # the word \"interaction\" does not appear in the dictionary and is ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-06 15:59:12,714 : INFO : storing corpus in Matrix Market format to /tmp/deerwester.mm\n",
      "2018-08-06 15:59:12,717 : INFO : saving sparse matrix to /tmp/deerwester.mm\n",
      "2018-08-06 15:59:12,719 : INFO : PROGRESS: saving document #0\n",
      "2018-08-06 15:59:12,721 : INFO : saved 9x12 matrix, density=25.926% (28/108)\n",
      "2018-08-06 15:59:12,722 : INFO : saving MmCorpus index to /tmp/deerwester.mm.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1)],\n",
      " [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)],\n",
      " [(2, 1), (5, 1), (7, 1), (8, 1)],\n",
      " [(1, 1), (5, 2), (8, 1)],\n",
      " [(3, 1), (6, 1), (7, 1)],\n",
      " [(9, 1)],\n",
      " [(9, 1), (10, 1)],\n",
      " [(9, 1), (10, 1), (11, 1)],\n",
      " [(4, 1), (10, 1), (11, 1)]]\n"
     ]
    }
   ],
   "source": [
    ">>> corpus = [dictionary.doc2bow(text) for text in texts]\n",
    ">>> corpora.MmCorpus.serialize('/tmp/deerwester.mm', corpus)  # store to disk, for later use\n",
    ">>> pprint(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# >>> from gensim import corpora, models, similarities\n",
    "# >>> if (os.path.exists(\"/tmp/deerwester.dict\")):\n",
    "# >>>    dictionary = corpora.Dictionary.load('/tmp/deerwester.dict')\n",
    "# >>>    corpus = corpora.MmCorpus('/tmp/deerwester.mm')\n",
    "# >>>    print(\"Used files generated from first tutorial\")\n",
    "# >>> else:\n",
    "# >>>    print(\"Please run first tutorial to generate data set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-06 16:01:07,401 : INFO : collecting document frequencies\n",
      "2018-08-06 16:01:07,405 : INFO : PROGRESS: processing document #0\n",
      "2018-08-06 16:01:07,410 : INFO : calculating IDF weights for 9 documents and 11 features (28 matrix non-zeros)\n"
     ]
    }
   ],
   "source": [
    ">>> tfidf = models.TfidfModel(corpus) # step 1 -- initialize a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.70710678118654757), (1, 0.70710678118654757)]\n"
     ]
    }
   ],
   "source": [
    ">>> doc_bow = [(0, 1), (1, 1)] # new_vec coming from document 1\n",
    ">>> print(tfidf[doc_bow]) # step 2 -- use the model to transform vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.57735026918962573), (1, 0.57735026918962573), (2, 0.57735026918962573)]\n",
      "[(0, 0.44424552527467476), (3, 0.44424552527467476), (4, 0.44424552527467476), (5, 0.32448702061385548), (6, 0.44424552527467476), (7, 0.32448702061385548)]\n",
      "[(2, 0.5710059809418182), (5, 0.41707573620227772), (7, 0.41707573620227772), (8, 0.5710059809418182)]\n",
      "[(1, 0.49182558987264147), (5, 0.71848116070837686), (8, 0.49182558987264147)]\n",
      "[(3, 0.62825804686700459), (6, 0.62825804686700459), (7, 0.45889394536615247)]\n",
      "[(9, 1.0)]\n",
      "[(9, 0.70710678118654746), (10, 0.70710678118654746)]\n",
      "[(9, 0.50804290089167492), (10, 0.50804290089167492), (11, 0.69554641952003704)]\n",
      "[(4, 0.62825804686700459), (10, 0.45889394536615247), (11, 0.62825804686700459)]\n"
     ]
    }
   ],
   "source": [
    ">>> corpus_tfidf = tfidf[corpus]\n",
    ">>> for doc in corpus_tfidf:\n",
    "...     print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-06 16:29:28,516 : INFO : using serial LSI version on this node\n",
      "2018-08-06 16:29:28,521 : INFO : updating model with new documents\n",
      "2018-08-06 16:29:28,526 : INFO : preparing a new chunk of documents\n",
      "2018-08-06 16:29:28,529 : INFO : using 100 extra samples and 2 power iterations\n",
      "2018-08-06 16:29:28,531 : INFO : 1st phase: constructing (12, 103) action matrix\n",
      "2018-08-06 16:29:28,533 : INFO : orthonormalizing (12, 103) action matrix\n",
      "2018-08-06 16:29:28,536 : INFO : 2nd phase: running dense svd on (12, 9) matrix\n",
      "2018-08-06 16:29:28,539 : INFO : computing the final decomposition\n",
      "2018-08-06 16:29:28,541 : INFO : keeping 3 factors (discarding 31.801% of energy spectrum)\n",
      "2018-08-06 16:29:28,542 : INFO : processed documents up to #9\n",
      "2018-08-06 16:29:28,543 : INFO : topic #0(1.594): -0.703*\"trees\" + -0.538*\"graph\" + -0.402*\"minors\" + -0.187*\"survey\" + -0.061*\"system\" + -0.060*\"time\" + -0.060*\"response\" + -0.058*\"user\" + -0.049*\"computer\" + -0.035*\"interface\"\n",
      "2018-08-06 16:29:28,545 : INFO : topic #1(1.476): -0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"time\" + -0.320*\"response\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"\n",
      "2018-08-06 16:29:28,546 : INFO : topic #2(1.191): 0.456*\"time\" + 0.456*\"response\" + -0.352*\"eps\" + -0.340*\"human\" + -0.318*\"interface\" + -0.277*\"system\" + 0.272*\"survey\" + 0.213*\"user\" + -0.183*\"trees\" + 0.114*\"minors\"\n"
     ]
    }
   ],
   "source": [
    ">>> lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=3) # initialize an LSI transformation\n",
    ">>> corpus_lsi = lsi[corpus_tfidf] # create a double wrapper over the original corpus: bow->tfidf->fold-in-lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-08-06 16:29:34,648 : INFO : topic #0(1.594): -0.703*\"trees\" + -0.538*\"graph\" + -0.402*\"minors\" + -0.187*\"survey\" + -0.061*\"system\" + -0.060*\"time\" + -0.060*\"response\" + -0.058*\"user\" + -0.049*\"computer\" + -0.035*\"interface\"\n",
      "2018-08-06 16:29:34,656 : INFO : topic #1(1.476): -0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"time\" + -0.320*\"response\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"\n",
      "2018-08-06 16:29:34,657 : INFO : topic #2(1.191): 0.456*\"time\" + 0.456*\"response\" + -0.352*\"eps\" + -0.340*\"human\" + -0.318*\"interface\" + -0.277*\"system\" + 0.272*\"survey\" + 0.213*\"user\" + -0.183*\"trees\" + 0.114*\"minors\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '-0.703*\"trees\" + -0.538*\"graph\" + -0.402*\"minors\" + -0.187*\"survey\" + -0.061*\"system\" + -0.060*\"time\" + -0.060*\"response\" + -0.058*\"user\" + -0.049*\"computer\" + -0.035*\"interface\"'),\n",
       " (1,\n",
       "  '-0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"time\" + -0.320*\"response\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"'),\n",
       " (2,\n",
       "  '0.456*\"time\" + 0.456*\"response\" + -0.352*\"eps\" + -0.340*\"human\" + -0.318*\"interface\" + -0.277*\"system\" + 0.272*\"survey\" + 0.213*\"user\" + -0.183*\"trees\" + 0.114*\"minors\"')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> lsi.print_topics(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, -0.066007833960905093), (1, -0.52007033063618413), (2, -0.37649581219168937)]\n",
      "[(0, -0.19667592859142732), (1, -0.76095631677000486), (2, 0.50806745810016563)]\n",
      "[(0, -0.089926399724467088), (1, -0.72418606267525032), (2, -0.40898973155376483)]\n",
      "[(0, -0.075858476521784221), (1, -0.632055158600342), (2, -0.53935336057338967)]\n",
      "[(0, -0.1015029918498031), (1, -0.57373084830029608), (2, 0.67093385852958987)]\n",
      "[(0, -0.70321089393783032), (1, 0.1611518021402604), (2, -0.18266089635241509)]\n",
      "[(0, -0.87747876731198238), (1, 0.16758906864659689), (2, -0.10880822642632884)]\n",
      "[(0, -0.90986246868185705), (1, 0.14086553628719281), (2, 0.00087117874886882829)]\n",
      "[(0, -0.61658253505692806), (1, -0.053929075663892309), (2, 0.25568697959599385)]\n"
     ]
    }
   ],
   "source": [
    ">>> for doc in corpus_lsi: # both bow->tfidf and tfidf->lsi transformations are actually executed here, on the fly\n",
    "...     print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
