{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Podcast 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from string import punctuation\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/aux/podcasts/transcriptions/3.txt') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = []\n",
    "for c in text:\n",
    "    if not c.isalnum():\n",
    "        chars.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = set(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/stopwords/spanish_stopwords.txt') as f:\n",
    "    sp_stopwords = list(set(map(str.strip, f.readlines())))\n",
    "\n",
    "with open('data/stopwords/my_stopwords.txt') as f:\n",
    "    my_stopwords = list(set(map(str.strip, f.readlines())))\n",
    "\n",
    "stop = stopwords.words('spanish') + sp_stopwords + my_stopwords + list(punctuation) + list(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean1(s):\n",
    "    r = s.lower().strip()\n",
    "    rs = [w for w in nltk.word_tokenize(r) if w not in stop and len(w) > 2]\n",
    "    r = ' '.join(rs)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = clean1(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1338\n",
      ". 1\n"
     ]
    }
   ],
   "source": [
    "for c in characters:\n",
    "    if c in cleaned_text:\n",
    "        print(c, cleaned_text.count(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean2(s):\n",
    "    r = s\n",
    "    r = r.replace('¿', '')\n",
    "    r = r.replace('‑', '-')\n",
    "    r = r.replace('¡', '')\n",
    "    r = r.replace('—', '')\n",
    "    r = r.replace('-', '-')\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = clean2(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(cleaned_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('niños', 27),\n",
       " ('palabras', 19),\n",
       " ('lugar', 15),\n",
       " ('hablar', 13),\n",
       " ('lengua', 13),\n",
       " ('literatura', 12),\n",
       " ('adultos', 12),\n",
       " ('infancia', 10),\n",
       " ('bueno', 9),\n",
       " ('niño', 9),\n",
       " ('paz', 9),\n",
       " ('palabra', 8),\n",
       " ('difíciles', 8),\n",
       " ('abuela', 7),\n",
       " ('vida', 7),\n",
       " ('símbolos', 7),\n",
       " ('hablando', 7),\n",
       " ('años', 7),\n",
       " ('infantil', 6),\n",
       " ('noche', 6),\n",
       " ('vez', 6),\n",
       " ('relato', 6),\n",
       " ('ahora', 6),\n",
       " ('ojos', 6),\n",
       " ('ahí', 6),\n",
       " ('pensar', 6),\n",
       " ('voz', 6),\n",
       " ('único', 5),\n",
       " ('pues', 5),\n",
       " ('generación', 5),\n",
       " ('bosque', 5),\n",
       " ('todavía', 5),\n",
       " ('escritores', 5),\n",
       " ('lectura', 5),\n",
       " ('habla', 5),\n",
       " ('papás', 5),\n",
       " ('libro', 5),\n",
       " ('negros', 5),\n",
       " ('escritura', 5),\n",
       " ('agujeros', 5),\n",
       " ('quería', 5),\n",
       " ('siempre', 5),\n",
       " ('historia', 5),\n",
       " ('temas', 5),\n",
       " ('miedo', 5),\n",
       " ('distinto', 4),\n",
       " ('pregunta', 4),\n",
       " ('mundo', 4),\n",
       " ('importó', 4),\n",
       " ('necesitamos', 4),\n",
       " ('proyecto', 4),\n",
       " ('casa', 4),\n",
       " ('colombia', 4),\n",
       " ('hablamos', 4),\n",
       " ('días', 4),\n",
       " ('realidad', 4),\n",
       " ('silencios', 4),\n",
       " ('bien', 4),\n",
       " ('proceso', 3),\n",
       " ('importante', 3),\n",
       " ('alguien', 3),\n",
       " ('fácil', 3),\n",
       " ('padres', 3),\n",
       " ('escribir', 3),\n",
       " ('maneras', 3),\n",
       " ('dijeron', 3),\n",
       " ('juan', 3),\n",
       " ('nunca', 3),\n",
       " ('gracias', 3),\n",
       " ('ejemplo', 3),\n",
       " ('parte', 3),\n",
       " ('cierta', 3),\n",
       " ('permitieron', 3),\n",
       " ('emoción', 3),\n",
       " ('manera', 3),\n",
       " ('razón', 3),\n",
       " ('volvió', 3),\n",
       " ('derechos', 3),\n",
       " ('adultez', 3),\n",
       " ('día', 3),\n",
       " ('campesinos', 3),\n",
       " ('tiempos', 3),\n",
       " ('veces', 3),\n",
       " ('pienso', 3),\n",
       " ('nombrar', 3),\n",
       " ('yolanda', 3),\n",
       " ('gente', 3),\n",
       " ('igual', 3),\n",
       " ('necesidad', 3),\n",
       " ('iniquidad', 3),\n",
       " ('fáctica', 3),\n",
       " ('fondo', 3),\n",
       " ('simbólico', 3),\n",
       " ('trabajo', 3),\n",
       " ('salir', 3),\n",
       " ('campo', 3),\n",
       " ('agua', 3),\n",
       " ('lenguaje', 3),\n",
       " ('distintas', 3),\n",
       " ('público', 3)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/out/cleaned_podcast_3.txt', 'w') as f:\n",
    "    f.write(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
