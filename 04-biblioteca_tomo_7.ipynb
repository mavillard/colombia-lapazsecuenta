{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tomo 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from string import punctuation\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/aux/biblioteca/tomos/7.txt') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = []\n",
    "for c in text:\n",
    "    if not c.isalnum():\n",
    "        chars.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = set(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/stopwords/spanish_stopwords.txt') as f:\n",
    "    sp_stopwords = list(set(map(str.strip, f.readlines())))\n",
    "\n",
    "with open('data/stopwords/my_stopwords.txt') as f:\n",
    "    my_stopwords = list(set(map(str.strip, f.readlines())))\n",
    "\n",
    "stop = stopwords.words('spanish') + sp_stopwords + my_stopwords + list(punctuation) + list(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean1(s):\n",
    "    r = s.lower().strip()\n",
    "    rs = [w for w in nltk.word_tokenize(r) if w not in stop and len(w) > 2]\n",
    "    r = ' '.join(rs)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = clean1(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". 278\n",
      ", 27\n",
      "/ 62\n",
      "​ 3\n",
      "= 2\n",
      "_ 5\n",
      "– 11\n",
      "‑ 204\n",
      "— 244\n",
      "… 1\n",
      "¡ 8\n",
      "- 503\n",
      "› 1\n",
      "* 1\n",
      "  58026\n",
      "¿ 21\n",
      "́ 56\n",
      "̃ 3\n"
     ]
    }
   ],
   "source": [
    "for c in characters:\n",
    "    if c in cleaned_text:\n",
    "        print(c, cleaned_text.count(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean2(s):\n",
    "    r = s\n",
    "    r = r.replace('¿', '')\n",
    "    r = r.replace('‑', '-')\n",
    "    r = r.replace('¡', '')\n",
    "    r = r.replace('—', '')\n",
    "    r = r.replace('-', '-')\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = clean2(cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(cleaned_text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('paz', 1014),\n",
       " ('mujeres', 852),\n",
       " ('nacional', 675),\n",
       " ('participación', 602),\n",
       " ('mesa', 510),\n",
       " ('organizaciones', 501),\n",
       " ('género', 474),\n",
       " ('foro', 440),\n",
       " ('conversaciones', 404),\n",
       " ('acuerdo', 368),\n",
       " ('víctimas', 358),\n",
       " ('gobierno', 338),\n",
       " ('conflicto', 305),\n",
       " ('derechos', 293),\n",
       " ('proceso', 271),\n",
       " ('colombia', 266),\n",
       " ('propuestas', 261),\n",
       " ('enfoque', 232),\n",
       " ('construcción', 226),\n",
       " ('farc-ep', 217),\n",
       " ('subcomisión', 216),\n",
       " ('acuerdos', 201),\n",
       " ('participantes', 195),\n",
       " ('trabajo', 192),\n",
       " ('general', 191),\n",
       " ('desarrollo', 186),\n",
       " ('foros', 177),\n",
       " ('implementación', 174),\n",
       " ('comunidades', 168),\n",
       " ('personas', 165),\n",
       " ('pueblos', 164),\n",
       " ('habana', 162),\n",
       " ('indígenas', 161),\n",
       " ('política', 161),\n",
       " ('sociedad', 158),\n",
       " ('mesas', 156),\n",
       " ('fin', 155),\n",
       " ('diferentes', 152),\n",
       " ('violencia', 151),\n",
       " ('especial', 150),\n",
       " ('país', 144),\n",
       " ('manera', 144),\n",
       " ('final', 141),\n",
       " ('territorios', 140),\n",
       " ('representantes', 138),\n",
       " ('universidad', 135),\n",
       " ('naciones', 134),\n",
       " ('unidas', 132),\n",
       " ('sectores', 128),\n",
       " ('sociales', 127),\n",
       " ('delegación', 126),\n",
       " ('integral', 124),\n",
       " ('delegaciones', 122),\n",
       " ('cuenta', 120),\n",
       " ('territorial', 119),\n",
       " ('organización', 117),\n",
       " ('lgbti', 117),\n",
       " ('marco', 116),\n",
       " ('diálogo', 115),\n",
       " ('parte', 114),\n",
       " ('regionales', 113),\n",
       " ('comisión', 112),\n",
       " ('puntos', 109),\n",
       " ('civil', 103),\n",
       " ('actores', 102),\n",
       " ('sexual', 101),\n",
       " ('nacionales', 100),\n",
       " ('comunicado', 99),\n",
       " ('mujer', 98),\n",
       " ('garantizar', 97),\n",
       " ('movimientos', 96),\n",
       " ('espacios', 95),\n",
       " ('hombres', 95),\n",
       " ('mecanismos', 93),\n",
       " ('medidas', 92),\n",
       " ('humanos', 92),\n",
       " ('políticos', 91),\n",
       " ('agenda', 90),\n",
       " ('través', 89),\n",
       " ('población', 88),\n",
       " ('social', 88),\n",
       " ('iniciativas', 85),\n",
       " ('sector', 85),\n",
       " ('conjunto', 84),\n",
       " ('grupos', 83),\n",
       " ('información', 82),\n",
       " ('armado', 82),\n",
       " ('internacional', 82),\n",
       " ('onu', 81),\n",
       " ('drogas', 81),\n",
       " ('internacionales', 81),\n",
       " ('seguimiento', 80),\n",
       " ('pedagogía', 80),\n",
       " ('mayor', 79),\n",
       " ('maría', 78),\n",
       " ('tres', 78),\n",
       " ('base', 78),\n",
       " ('equipo', 78),\n",
       " ('seguridad', 78),\n",
       " ('procesos', 77)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/out/cleaned_tomo_7.txt', 'w') as f:\n",
    "    f.write(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
