{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tomo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "from pprint import pprint\n",
    "from string import punctuation\n",
    "\n",
    "import nltk\n",
    "import numpy as np\n",
    "from gensim import corpora, models\n",
    "from nltk.corpus import stopwords\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def key_sort_files(x):\n",
    "    return int(x[:-4].split('-')[0])\n",
    "\n",
    "path = 'data/aux/biblioteca/text_parts/7/'\n",
    "unsorted_file_list = [filename for filename in os.listdir(path) if filename.endswith('.txt')]\n",
    "file_list = sorted(unsorted_file_list, key=key_sort_files)\n",
    "\n",
    "raw_texts = []\n",
    "for filename in file_list:\n",
    "    with open(path + filename) as f:\n",
    "        raw_texts.append(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chars = []\n",
    "for text in raw_texts:\n",
    "    for c in text:\n",
    "        if not c.isalnum():\n",
    "            chars.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "characters = set(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/stopwords/spanish_stopwords.txt') as f:\n",
    "    sp_stopwords = list(set(map(str.strip, f.readlines())))\n",
    "\n",
    "with open('data/stopwords/my_stopwords.txt') as f:\n",
    "    my_stopwords = list(set(map(str.strip, f.readlines())))\n",
    "\n",
    "stop = stopwords.words('spanish') + sp_stopwords + my_stopwords + list(punctuation) + list(characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(s):\n",
    "    r = s.lower().strip()\n",
    "    for c in characters:\n",
    "        r = r.replace(c, ' ')\n",
    "    r = r.replace('farc ep', 'farc-ep')\n",
    "    r = r.replace('confianz a', 'confianza')\n",
    "    r = r.replace('cons trucción', 'construcción')\n",
    "    rs = [w for w in nltk.word_tokenize(r) if w not in stop and len(w) > 2 and not w.isdecimal()]\n",
    "    r = ' '.join(rs)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cleaned_texts = [clean(text) for text in raw_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int, {' ': 53855, '-': 200})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_counter = defaultdict(int)\n",
    "for c in characters:\n",
    "    for text in cleaned_texts:\n",
    "        if c in text:\n",
    "            char_counter[c]+=text.count(c)\n",
    "char_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "documents = cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "document = ' '.join(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only texts that contain MORE THAN or EQUALS TO 100 words\n",
    "texts = [[word for word in document.split()] for document in documents if len(document.split()) >= 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7829"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1 / 144 - MIN_DF: 1 - MAX_DF: 0.6 - MAX_FT: 100 - N_TOPICS: 10\n",
      "Iteration: 2 / 144 - MIN_DF: 1 - MAX_DF: 0.6 - MAX_FT: 100 - N_TOPICS: 46\n",
      "Iteration: 3 / 144 - MIN_DF: 1 - MAX_DF: 0.6 - MAX_FT: 100 - N_TOPICS: 100\n",
      "Iteration: 4 / 144 - MIN_DF: 1 - MAX_DF: 0.6 - MAX_FT: 1000 - N_TOPICS: 10\n",
      "Iteration: 5 / 144 - MIN_DF: 1 - MAX_DF: 0.6 - MAX_FT: 1000 - N_TOPICS: 46\n",
      "Iteration: 6 / 144 - MIN_DF: 1 - MAX_DF: 0.6 - MAX_FT: 1000 - N_TOPICS: 100\n",
      "Iteration: 7 / 144 - MIN_DF: 1 - MAX_DF: 0.6 - MAX_FT: 7829 - N_TOPICS: 10\n",
      "Iteration: 8 / 144 - MIN_DF: 1 - MAX_DF: 0.6 - MAX_FT: 7829 - N_TOPICS: 46\n",
      "Iteration: 9 / 144 - MIN_DF: 1 - MAX_DF: 0.6 - MAX_FT: 7829 - N_TOPICS: 100\n",
      "Iteration: 10 / 144 - MIN_DF: 1 - MAX_DF: 0.7 - MAX_FT: 100 - N_TOPICS: 10\n",
      "Iteration: 11 / 144 - MIN_DF: 1 - MAX_DF: 0.7 - MAX_FT: 100 - N_TOPICS: 46\n",
      "Iteration: 12 / 144 - MIN_DF: 1 - MAX_DF: 0.7 - MAX_FT: 100 - N_TOPICS: 100\n",
      "Iteration: 13 / 144 - MIN_DF: 1 - MAX_DF: 0.7 - MAX_FT: 1000 - N_TOPICS: 10\n",
      "Iteration: 14 / 144 - MIN_DF: 1 - MAX_DF: 0.7 - MAX_FT: 1000 - N_TOPICS: 46\n",
      "Iteration: 15 / 144 - MIN_DF: 1 - MAX_DF: 0.7 - MAX_FT: 1000 - N_TOPICS: 100\n",
      "Iteration: 16 / 144 - MIN_DF: 1 - MAX_DF: 0.7 - MAX_FT: 7829 - N_TOPICS: 10\n",
      "Iteration: 17 / 144 - MIN_DF: 1 - MAX_DF: 0.7 - MAX_FT: 7829 - N_TOPICS: 46\n",
      "Iteration: 18 / 144 - MIN_DF: 1 - MAX_DF: 0.7 - MAX_FT: 7829 - N_TOPICS: 100\n",
      "Iteration: 19 / 144 - MIN_DF: 1 - MAX_DF: 0.8 - MAX_FT: 100 - N_TOPICS: 10\n",
      "Iteration: 20 / 144 - MIN_DF: 1 - MAX_DF: 0.8 - MAX_FT: 100 - N_TOPICS: 46\n",
      "Iteration: 21 / 144 - MIN_DF: 1 - MAX_DF: 0.8 - MAX_FT: 100 - N_TOPICS: 100\n",
      "Iteration: 22 / 144 - MIN_DF: 1 - MAX_DF: 0.8 - MAX_FT: 1000 - N_TOPICS: 10\n",
      "Iteration: 23 / 144 - MIN_DF: 1 - MAX_DF: 0.8 - MAX_FT: 1000 - N_TOPICS: 46\n",
      "Iteration: 24 / 144 - MIN_DF: 1 - MAX_DF: 0.8 - MAX_FT: 1000 - N_TOPICS: 100\n",
      "Iteration: 25 / 144 - MIN_DF: 1 - MAX_DF: 0.8 - MAX_FT: 7829 - N_TOPICS: 10\n",
      "Iteration: 26 / 144 - MIN_DF: 1 - MAX_DF: 0.8 - MAX_FT: 7829 - N_TOPICS: 46\n",
      "Iteration: 27 / 144 - MIN_DF: 1 - MAX_DF: 0.8 - MAX_FT: 7829 - N_TOPICS: 100\n",
      "Iteration: 28 / 144 - MIN_DF: 1 - MAX_DF: 0.9 - MAX_FT: 100 - N_TOPICS: 10\n",
      "Iteration: 29 / 144 - MIN_DF: 1 - MAX_DF: 0.9 - MAX_FT: 100 - N_TOPICS: 46\n",
      "Iteration: 30 / 144 - MIN_DF: 1 - MAX_DF: 0.9 - MAX_FT: 100 - N_TOPICS: 100\n",
      "Iteration: 31 / 144 - MIN_DF: 1 - MAX_DF: 0.9 - MAX_FT: 1000 - N_TOPICS: 10\n",
      "Iteration: 32 / 144 - MIN_DF: 1 - MAX_DF: 0.9 - MAX_FT: 1000 - N_TOPICS: 46\n",
      "Iteration: 33 / 144 - MIN_DF: 1 - MAX_DF: 0.9 - MAX_FT: 1000 - N_TOPICS: 100\n",
      "Iteration: 34 / 144 - MIN_DF: 1 - MAX_DF: 0.9 - MAX_FT: 7829 - N_TOPICS: 10\n",
      "Iteration: 35 / 144 - MIN_DF: 1 - MAX_DF: 0.9 - MAX_FT: 7829 - N_TOPICS: 46\n",
      "Iteration: 36 / 144 - MIN_DF: 1 - MAX_DF: 0.9 - MAX_FT: 7829 - N_TOPICS: 100\n",
      "Iteration: 37 / 144 - MIN_DF: 2 - MAX_DF: 0.6 - MAX_FT: 100 - N_TOPICS: 10\n",
      "Iteration: 38 / 144 - MIN_DF: 2 - MAX_DF: 0.6 - MAX_FT: 100 - N_TOPICS: 46\n",
      "Iteration: 39 / 144 - MIN_DF: 2 - MAX_DF: 0.6 - MAX_FT: 100 - N_TOPICS: 100\n",
      "Iteration: 40 / 144 - MIN_DF: 2 - MAX_DF: 0.6 - MAX_FT: 1000 - N_TOPICS: 10\n",
      "Iteration: 41 / 144 - MIN_DF: 2 - MAX_DF: 0.6 - MAX_FT: 1000 - N_TOPICS: 46\n",
      "Iteration: 42 / 144 - MIN_DF: 2 - MAX_DF: 0.6 - MAX_FT: 1000 - N_TOPICS: 100\n",
      "Iteration: 43 / 144 - MIN_DF: 2 - MAX_DF: 0.6 - MAX_FT: 7829 - N_TOPICS: 10\n",
      "Iteration: 44 / 144 - MIN_DF: 2 - MAX_DF: 0.6 - MAX_FT: 7829 - N_TOPICS: 46\n",
      "Iteration: 45 / 144 - MIN_DF: 2 - MAX_DF: 0.6 - MAX_FT: 7829 - N_TOPICS: 100\n",
      "Iteration: 46 / 144 - MIN_DF: 2 - MAX_DF: 0.7 - MAX_FT: 100 - N_TOPICS: 10\n",
      "Iteration: 47 / 144 - MIN_DF: 2 - MAX_DF: 0.7 - MAX_FT: 100 - N_TOPICS: 46\n",
      "Iteration: 48 / 144 - MIN_DF: 2 - MAX_DF: 0.7 - MAX_FT: 100 - N_TOPICS: 100\n",
      "Iteration: 49 / 144 - MIN_DF: 2 - MAX_DF: 0.7 - MAX_FT: 1000 - N_TOPICS: 10\n",
      "Iteration: 50 / 144 - MIN_DF: 2 - MAX_DF: 0.7 - MAX_FT: 1000 - N_TOPICS: 46\n",
      "Iteration: 51 / 144 - MIN_DF: 2 - MAX_DF: 0.7 - MAX_FT: 1000 - N_TOPICS: 100\n",
      "Iteration: 52 / 144 - MIN_DF: 2 - MAX_DF: 0.7 - MAX_FT: 7829 - N_TOPICS: 10\n",
      "Iteration: 53 / 144 - MIN_DF: 2 - MAX_DF: 0.7 - MAX_FT: 7829 - N_TOPICS: 46\n",
      "Iteration: 54 / 144 - MIN_DF: 2 - MAX_DF: 0.7 - MAX_FT: 7829 - N_TOPICS: 100\n",
      "Iteration: 55 / 144 - MIN_DF: 2 - MAX_DF: 0.8 - MAX_FT: 100 - N_TOPICS: 10\n",
      "Iteration: 56 / 144 - MIN_DF: 2 - MAX_DF: 0.8 - MAX_FT: 100 - N_TOPICS: 46\n",
      "Iteration: 57 / 144 - MIN_DF: 2 - MAX_DF: 0.8 - MAX_FT: 100 - N_TOPICS: 100\n",
      "Iteration: 58 / 144 - MIN_DF: 2 - MAX_DF: 0.8 - MAX_FT: 1000 - N_TOPICS: 10\n",
      "Iteration: 59 / 144 - MIN_DF: 2 - MAX_DF: 0.8 - MAX_FT: 1000 - N_TOPICS: 46\n",
      "Iteration: 60 / 144 - MIN_DF: 2 - MAX_DF: 0.8 - MAX_FT: 1000 - N_TOPICS: 100\n",
      "Iteration: 61 / 144 - MIN_DF: 2 - MAX_DF: 0.8 - MAX_FT: 7829 - N_TOPICS: 10\n",
      "Iteration: 62 / 144 - MIN_DF: 2 - MAX_DF: 0.8 - MAX_FT: 7829 - N_TOPICS: 46\n",
      "Iteration: 63 / 144 - MIN_DF: 2 - MAX_DF: 0.8 - MAX_FT: 7829 - N_TOPICS: 100\n",
      "Iteration: 64 / 144 - MIN_DF: 2 - MAX_DF: 0.9 - MAX_FT: 100 - N_TOPICS: 10\n",
      "Iteration: 65 / 144 - MIN_DF: 2 - MAX_DF: 0.9 - MAX_FT: 100 - N_TOPICS: 46\n",
      "Iteration: 66 / 144 - MIN_DF: 2 - MAX_DF: 0.9 - MAX_FT: 100 - N_TOPICS: 100\n",
      "Iteration: 67 / 144 - MIN_DF: 2 - MAX_DF: 0.9 - MAX_FT: 1000 - N_TOPICS: 10\n",
      "Iteration: 68 / 144 - MIN_DF: 2 - MAX_DF: 0.9 - MAX_FT: 1000 - N_TOPICS: 46\n",
      "Iteration: 69 / 144 - MIN_DF: 2 - MAX_DF: 0.9 - MAX_FT: 1000 - N_TOPICS: 100\n",
      "Iteration: 70 / 144 - MIN_DF: 2 - MAX_DF: 0.9 - MAX_FT: 7829 - N_TOPICS: 10\n",
      "Iteration: 71 / 144 - MIN_DF: 2 - MAX_DF: 0.9 - MAX_FT: 7829 - N_TOPICS: 46\n",
      "Iteration: 72 / 144 - MIN_DF: 2 - MAX_DF: 0.9 - MAX_FT: 7829 - N_TOPICS: 100\n",
      "Iteration: 73 / 144 - MIN_DF: 4 - MAX_DF: 0.6 - MAX_FT: 100 - N_TOPICS: 10\n",
      "Iteration: 74 / 144 - MIN_DF: 4 - MAX_DF: 0.6 - MAX_FT: 100 - N_TOPICS: 46\n",
      "Iteration: 75 / 144 - MIN_DF: 4 - MAX_DF: 0.6 - MAX_FT: 100 - N_TOPICS: 100\n",
      "Iteration: 76 / 144 - MIN_DF: 4 - MAX_DF: 0.6 - MAX_FT: 1000 - N_TOPICS: 10\n",
      "Iteration: 77 / 144 - MIN_DF: 4 - MAX_DF: 0.6 - MAX_FT: 1000 - N_TOPICS: 46\n",
      "Iteration: 78 / 144 - MIN_DF: 4 - MAX_DF: 0.6 - MAX_FT: 1000 - N_TOPICS: 100\n",
      "Iteration: 79 / 144 - MIN_DF: 4 - MAX_DF: 0.6 - MAX_FT: 7829 - N_TOPICS: 10\n",
      "Iteration: 80 / 144 - MIN_DF: 4 - MAX_DF: 0.6 - MAX_FT: 7829 - N_TOPICS: 46\n",
      "Iteration: 81 / 144 - MIN_DF: 4 - MAX_DF: 0.6 - MAX_FT: 7829 - N_TOPICS: 100\n",
      "Iteration: 82 / 144 - MIN_DF: 4 - MAX_DF: 0.7 - MAX_FT: 100 - N_TOPICS: 10\n",
      "Iteration: 83 / 144 - MIN_DF: 4 - MAX_DF: 0.7 - MAX_FT: 100 - N_TOPICS: 46\n",
      "Iteration: 84 / 144 - MIN_DF: 4 - MAX_DF: 0.7 - MAX_FT: 100 - N_TOPICS: 100\n",
      "Iteration: 85 / 144 - MIN_DF: 4 - MAX_DF: 0.7 - MAX_FT: 1000 - N_TOPICS: 10\n",
      "Iteration: 86 / 144 - MIN_DF: 4 - MAX_DF: 0.7 - MAX_FT: 1000 - N_TOPICS: 46\n",
      "Iteration: 87 / 144 - MIN_DF: 4 - MAX_DF: 0.7 - MAX_FT: 1000 - N_TOPICS: 100\n",
      "Iteration: 88 / 144 - MIN_DF: 4 - MAX_DF: 0.7 - MAX_FT: 7829 - N_TOPICS: 10\n",
      "Iteration: 89 / 144 - MIN_DF: 4 - MAX_DF: 0.7 - MAX_FT: 7829 - N_TOPICS: 46\n",
      "Iteration: 90 / 144 - MIN_DF: 4 - MAX_DF: 0.7 - MAX_FT: 7829 - N_TOPICS: 100\n",
      "Iteration: 91 / 144 - MIN_DF: 4 - MAX_DF: 0.8 - MAX_FT: 100 - N_TOPICS: 10\n",
      "Iteration: 92 / 144 - MIN_DF: 4 - MAX_DF: 0.8 - MAX_FT: 100 - N_TOPICS: 46\n",
      "Iteration: 93 / 144 - MIN_DF: 4 - MAX_DF: 0.8 - MAX_FT: 100 - N_TOPICS: 100\n",
      "Iteration: 94 / 144 - MIN_DF: 4 - MAX_DF: 0.8 - MAX_FT: 1000 - N_TOPICS: 10\n",
      "Iteration: 95 / 144 - MIN_DF: 4 - MAX_DF: 0.8 - MAX_FT: 1000 - N_TOPICS: 46\n",
      "Iteration: 96 / 144 - MIN_DF: 4 - MAX_DF: 0.8 - MAX_FT: 1000 - N_TOPICS: 100\n",
      "Iteration: 97 / 144 - MIN_DF: 4 - MAX_DF: 0.8 - MAX_FT: 7829 - N_TOPICS: 10\n",
      "Iteration: 98 / 144 - MIN_DF: 4 - MAX_DF: 0.8 - MAX_FT: 7829 - N_TOPICS: 46\n",
      "Iteration: 99 / 144 - MIN_DF: 4 - MAX_DF: 0.8 - MAX_FT: 7829 - N_TOPICS: 100\n",
      "Iteration: 100 / 144 - MIN_DF: 4 - MAX_DF: 0.9 - MAX_FT: 100 - N_TOPICS: 10\n",
      "Iteration: 101 / 144 - MIN_DF: 4 - MAX_DF: 0.9 - MAX_FT: 100 - N_TOPICS: 46\n",
      "Iteration: 102 / 144 - MIN_DF: 4 - MAX_DF: 0.9 - MAX_FT: 100 - N_TOPICS: 100\n",
      "Iteration: 103 / 144 - MIN_DF: 4 - MAX_DF: 0.9 - MAX_FT: 1000 - N_TOPICS: 10\n",
      "Iteration: 104 / 144 - MIN_DF: 4 - MAX_DF: 0.9 - MAX_FT: 1000 - N_TOPICS: 46\n",
      "Iteration: 105 / 144 - MIN_DF: 4 - MAX_DF: 0.9 - MAX_FT: 1000 - N_TOPICS: 100\n",
      "Iteration: 106 / 144 - MIN_DF: 4 - MAX_DF: 0.9 - MAX_FT: 7829 - N_TOPICS: 10\n",
      "Iteration: 107 / 144 - MIN_DF: 4 - MAX_DF: 0.9 - MAX_FT: 7829 - N_TOPICS: 46\n",
      "Iteration: 108 / 144 - MIN_DF: 4 - MAX_DF: 0.9 - MAX_FT: 7829 - N_TOPICS: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 109 / 144 - MIN_DF: 7 - MAX_DF: 0.6 - MAX_FT: 100 - N_TOPICS: 10\n",
      "Iteration: 110 / 144 - MIN_DF: 7 - MAX_DF: 0.6 - MAX_FT: 100 - N_TOPICS: 46\n",
      "Iteration: 111 / 144 - MIN_DF: 7 - MAX_DF: 0.6 - MAX_FT: 100 - N_TOPICS: 100\n",
      "Iteration: 112 / 144 - MIN_DF: 7 - MAX_DF: 0.6 - MAX_FT: 1000 - N_TOPICS: 10\n",
      "Iteration: 113 / 144 - MIN_DF: 7 - MAX_DF: 0.6 - MAX_FT: 1000 - N_TOPICS: 46\n",
      "Iteration: 114 / 144 - MIN_DF: 7 - MAX_DF: 0.6 - MAX_FT: 1000 - N_TOPICS: 100\n",
      "Iteration: 115 / 144 - MIN_DF: 7 - MAX_DF: 0.6 - MAX_FT: 7829 - N_TOPICS: 10\n",
      "Iteration: 116 / 144 - MIN_DF: 7 - MAX_DF: 0.6 - MAX_FT: 7829 - N_TOPICS: 46\n",
      "Iteration: 117 / 144 - MIN_DF: 7 - MAX_DF: 0.6 - MAX_FT: 7829 - N_TOPICS: 100\n",
      "Iteration: 118 / 144 - MIN_DF: 7 - MAX_DF: 0.7 - MAX_FT: 100 - N_TOPICS: 10\n",
      "Iteration: 119 / 144 - MIN_DF: 7 - MAX_DF: 0.7 - MAX_FT: 100 - N_TOPICS: 46\n",
      "Iteration: 120 / 144 - MIN_DF: 7 - MAX_DF: 0.7 - MAX_FT: 100 - N_TOPICS: 100\n",
      "Iteration: 121 / 144 - MIN_DF: 7 - MAX_DF: 0.7 - MAX_FT: 1000 - N_TOPICS: 10\n",
      "Iteration: 122 / 144 - MIN_DF: 7 - MAX_DF: 0.7 - MAX_FT: 1000 - N_TOPICS: 46\n",
      "Iteration: 123 / 144 - MIN_DF: 7 - MAX_DF: 0.7 - MAX_FT: 1000 - N_TOPICS: 100\n",
      "Iteration: 124 / 144 - MIN_DF: 7 - MAX_DF: 0.7 - MAX_FT: 7829 - N_TOPICS: 10\n",
      "Iteration: 125 / 144 - MIN_DF: 7 - MAX_DF: 0.7 - MAX_FT: 7829 - N_TOPICS: 46\n",
      "Iteration: 126 / 144 - MIN_DF: 7 - MAX_DF: 0.7 - MAX_FT: 7829 - N_TOPICS: 100\n",
      "Iteration: 127 / 144 - MIN_DF: 7 - MAX_DF: 0.8 - MAX_FT: 100 - N_TOPICS: 10\n",
      "Iteration: 128 / 144 - MIN_DF: 7 - MAX_DF: 0.8 - MAX_FT: 100 - N_TOPICS: 46\n",
      "Iteration: 129 / 144 - MIN_DF: 7 - MAX_DF: 0.8 - MAX_FT: 100 - N_TOPICS: 100\n",
      "Iteration: 130 / 144 - MIN_DF: 7 - MAX_DF: 0.8 - MAX_FT: 1000 - N_TOPICS: 10\n",
      "Iteration: 131 / 144 - MIN_DF: 7 - MAX_DF: 0.8 - MAX_FT: 1000 - N_TOPICS: 46\n",
      "Iteration: 132 / 144 - MIN_DF: 7 - MAX_DF: 0.8 - MAX_FT: 1000 - N_TOPICS: 100\n",
      "Iteration: 133 / 144 - MIN_DF: 7 - MAX_DF: 0.8 - MAX_FT: 7829 - N_TOPICS: 10\n",
      "Iteration: 134 / 144 - MIN_DF: 7 - MAX_DF: 0.8 - MAX_FT: 7829 - N_TOPICS: 46\n",
      "Iteration: 135 / 144 - MIN_DF: 7 - MAX_DF: 0.8 - MAX_FT: 7829 - N_TOPICS: 100\n",
      "Iteration: 136 / 144 - MIN_DF: 7 - MAX_DF: 0.9 - MAX_FT: 100 - N_TOPICS: 10\n",
      "Iteration: 137 / 144 - MIN_DF: 7 - MAX_DF: 0.9 - MAX_FT: 100 - N_TOPICS: 46\n",
      "Iteration: 138 / 144 - MIN_DF: 7 - MAX_DF: 0.9 - MAX_FT: 100 - N_TOPICS: 100\n",
      "Iteration: 139 / 144 - MIN_DF: 7 - MAX_DF: 0.9 - MAX_FT: 1000 - N_TOPICS: 10\n",
      "Iteration: 140 / 144 - MIN_DF: 7 - MAX_DF: 0.9 - MAX_FT: 1000 - N_TOPICS: 46\n",
      "Iteration: 141 / 144 - MIN_DF: 7 - MAX_DF: 0.9 - MAX_FT: 1000 - N_TOPICS: 100\n",
      "Iteration: 142 / 144 - MIN_DF: 7 - MAX_DF: 0.9 - MAX_FT: 7829 - N_TOPICS: 10\n",
      "Iteration: 143 / 144 - MIN_DF: 7 - MAX_DF: 0.9 - MAX_FT: 7829 - N_TOPICS: 46\n",
      "Iteration: 144 / 144 - MIN_DF: 7 - MAX_DF: 0.9 - MAX_FT: 7829 - N_TOPICS: 100\n",
      "CPU times: user 2min 48s, sys: 1min 54s, total: 4min 43s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# lsi_topics_lists = []\n",
    "lda_topics_lists = []\n",
    "hdp_topics_lists = []\n",
    "\n",
    "MIN_DFs = [1, 2, 4, 7]\n",
    "MAX_DFs = [0.6, 0.7, 0.8, 0.9]\n",
    "MAX_FTs = [100, 1000, len(dictionary)]\n",
    "N_TOPICSs = [10, len(texts), 100]\n",
    "\n",
    "total_iterations = len(MIN_DFs) * len(MAX_DFs) * len(MAX_FTs) * len(N_TOPICSs)\n",
    "iteration = 1\n",
    "for MIN_DF in MIN_DFs:\n",
    "    for MAX_DF in MAX_DFs:\n",
    "        for MAX_FT in MAX_FTs:\n",
    "            dictionary = corpora.Dictionary(texts)\n",
    "            dictionary.filter_extremes(no_below=MIN_DF, no_above=MAX_DF, keep_n=MAX_FT)\n",
    "            corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "            tfidf = models.TfidfModel(corpus)\n",
    "            corpus_tfidf = tfidf[corpus]\n",
    "            \n",
    "            for N_TOPICS in N_TOPICSs:\n",
    "                print('Iteration: {} / {}'.format(iteration, total_iterations), \\\n",
    "                      '- MIN_DF:', MIN_DF, '- MAX_DF:', MAX_DF, '- MAX_FT:', MAX_FT, '- N_TOPICS:', N_TOPICS)\n",
    "                iteration += 1\n",
    "                \n",
    "                # LSI\n",
    "#                 lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=N_TOPICS)\n",
    "#                 corpus_lsi = lsi[corpus_tfidf]\n",
    "#                 ts = lsi.show_topics(lsi.num_topics, formatted=False)\n",
    "#                 result = (ts, (MIN_DF, MAX_DF, MAX_FT, N_TOPICS), corpus_lsi)\n",
    "#                 lsi_topics_lists.append(result)\n",
    "            \n",
    "                # LDA\n",
    "                lda = models.LdaModel(corpus, id2word=dictionary, num_topics=N_TOPICS, random_state=0)\n",
    "                corpus_lda = lda[corpus]\n",
    "                ts = sorted(lda.show_topics(lda.num_topics, formatted=False))\n",
    "                result = (ts, (MIN_DF, MAX_DF, MAX_FT, N_TOPICS), corpus_lda)\n",
    "                lda_topics_lists.append(result)\n",
    "            \n",
    "                # HDP\n",
    "                hdp = models.HdpModel(corpus, id2word=dictionary, random_state=0)\n",
    "                corpus_hdp = hdp[corpus]\n",
    "                ts = hdp.show_topics(len(hdp.show_topics(num_topics=-1)), num_words=10, formatted=False)\n",
    "                result = (ts, (MIN_DF, MAX_DF, MAX_FT, N_TOPICS), corpus_hdp)\n",
    "                hdp_topics_lists.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_vocabulary(ts):\n",
    "    vocab = set()\n",
    "    for t in ts:\n",
    "        words = [word for word, weight in t]\n",
    "        vocab = vocab.union(words)\n",
    "    vocab = sorted(vocab)\n",
    "    r = {w: i for i, w in enumerate(vocab)}\n",
    "    return r\n",
    "\n",
    "def get_weights(t):\n",
    "    return dict(t)\n",
    "\n",
    "def create_vector(vocab, weights):\n",
    "    r = [0] * len(vocab)\n",
    "    for wo in weights:\n",
    "        r[vocab[wo]] = weights[wo]\n",
    "    return r\n",
    "\n",
    "def vectorize(ts):\n",
    "    r = []\n",
    "    ts = [t for i, j, t in ts]\n",
    "    vocab = extract_vocabulary(ts)\n",
    "    for t in ts:\n",
    "        weights = get_weights(t)\n",
    "        vector = create_vector(vocab, weights)\n",
    "        r.append(vector)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def two_topics_distance(t1, t2):\n",
    "    r = spatial.distance.cosine(t1, t2)\n",
    "    return r\n",
    "\n",
    "def multiple_topics_distance(ts):\n",
    "    ds = []\n",
    "    for i, t1 in enumerate(ts[:-1]):\n",
    "        for j in range(i + 1, len(ts)):\n",
    "            t2 = ts[j]\n",
    "            d = two_topics_distance(t1, t2)\n",
    "            ds.append(d)\n",
    "    return np.mean(ds)\n",
    "\n",
    "def top_n_used(ts_list, n):\n",
    "    total_weights = defaultdict(float)\n",
    "    corpus = ts_list[2]\n",
    "    for doc in corpus:\n",
    "        for topic, weight in doc:\n",
    "            total_weights[topic] += abs(weight)\n",
    "    total_weights = dict(total_weights)\n",
    "    counter = Counter(total_weights)\n",
    "    topics_dct = dict(ts_list[0])\n",
    "    r = ([(weight, topic_id, topics_dct[topic_id])\n",
    "             for topic_id, weight in counter.most_common(n)], ts_list[1], corpus)\n",
    "    return r\n",
    "\n",
    "def best_topics(ts_lists, n=10):\n",
    "    r = []\n",
    "    for ts_list in ts_lists:\n",
    "        top_n_ts_list = top_n_used(ts_list, n)\n",
    "        ts_vector = vectorize(top_n_ts_list[0])\n",
    "        d = multiple_topics_distance(ts_vector)\n",
    "        r.append((d, top_n_ts_list))\n",
    "    r = sorted(r, reverse=True)\n",
    "    return r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA\n",
      "HDP\n",
      "CPU times: user 1min 14s, sys: 1min 14s, total: 2min 28s\n",
      "Wall time: 38.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# print('LSI')\n",
    "# lsi_best_topics_list = best_topics(lsi_topics_lists)\n",
    "print('LDA')\n",
    "lda_best_topics_list = best_topics(lda_topics_lists)\n",
    "print('HDP')\n",
    "hdp_best_topics_list = best_topics(hdp_topics_lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lsi_best_topics_list[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2.9281185753643513,\n",
       "  49,\n",
       "  [('foro', 0.014351286),\n",
       "   ('pueblos', 0.012354096),\n",
       "   ('consultas', 0.011176488),\n",
       "   ('mesas', 0.0096873445),\n",
       "   ('representantes', 0.0090755615),\n",
       "   ('comunidades', 0.0084993485),\n",
       "   ('organización', 0.0078254649),\n",
       "   ('participantes', 0.0075355857),\n",
       "   ('étnico', 0.0069663241),\n",
       "   ('comisión', 0.0066033257)]),\n",
       " (2.8275989601388574,\n",
       "  68,\n",
       "  [('territorios', 0.025001768),\n",
       "   ('inicio', 0.022780633),\n",
       "   ('pedagogía', 0.021334987),\n",
       "   ('foro', 0.017387316),\n",
       "   ('territorial', 0.015666567),\n",
       "   ('capacidades', 0.013118932),\n",
       "   ('proyecto', 0.012521289),\n",
       "   ('actores', 0.010379532),\n",
       "   ('diálogos', 0.010261009),\n",
       "   ('convivencia', 0.0095848795)]),\n",
       " (2.400023702532053,\n",
       "  10,\n",
       "  [('pueblos', 0.025529699),\n",
       "   ('territorios', 0.014066815),\n",
       "   ('étnica', 0.012898666),\n",
       "   ('étnico', 0.012449214),\n",
       "   ('comisión', 0.011285299),\n",
       "   ('étnicos', 0.011060828),\n",
       "   ('capítulo', 0.011057509),\n",
       "   ('afrodescendientes', 0.0080890832),\n",
       "   ('territoriales', 0.0076786876),\n",
       "   ('pedagogía', 0.007368308)]),\n",
       " (2.2154590934514999,\n",
       "  94,\n",
       "  [('violencia', 0.010715495),\n",
       "   ('comunidades', 0.010705614),\n",
       "   ('mujer', 0.010317109),\n",
       "   ('hombres', 0.0091081848),\n",
       "   ('medidas', 0.0090080667),\n",
       "   ('especial', 0.0088255312),\n",
       "   ('igualdad', 0.0085722981),\n",
       "   ('población', 0.008390394),\n",
       "   ('comisión', 0.0082817664),\n",
       "   ('cuenta', 0.0082629239)]),\n",
       " (2.2139930874109268,\n",
       "  5,\n",
       "  [('foro', 0.041618925),\n",
       "   ('sectores', 0.015339894),\n",
       "   ('mesas', 0.015046922),\n",
       "   ('participantes', 0.014640943),\n",
       "   ('diferentes', 0.012337844),\n",
       "   ('universidad', 0.010072473),\n",
       "   ('importantes', 0.0098231276),\n",
       "   ('sector', 0.0096799126),\n",
       "   ('actores', 0.0089904182),\n",
       "   ('base', 0.0084086927)]),\n",
       " (1.7632102761417627,\n",
       "  82,\n",
       "  [('violencia', 0.036526807),\n",
       "   ('sexual', 0.028498363),\n",
       "   ('medidas', 0.018635837),\n",
       "   ('niñas', 0.017064115),\n",
       "   ('mujer', 0.0095591443),\n",
       "   ('mecanismos', 0.0091489507),\n",
       "   ('armado', 0.0086855749),\n",
       "   ('naciones', 0.0086053647),\n",
       "   ('maría', 0.0083738016),\n",
       "   ('través', 0.0082089286)]),\n",
       " (1.6854717750102282,\n",
       "  34,\n",
       "  [('foro', 0.03903066),\n",
       "   ('participantes', 0.014744411),\n",
       "   ('universidad', 0.013584896),\n",
       "   ('mesas', 0.011044248),\n",
       "   ('importantes', 0.010314946),\n",
       "   ('actores', 0.010205052),\n",
       "   ('políticos', 0.0090580443),\n",
       "   ('sectores', 0.008934333),\n",
       "   ('sociales', 0.0086090267),\n",
       "   ('diferentes', 0.0083588567)]),\n",
       " (1.6285290643572807,\n",
       "  44,\n",
       "  [('decisiones', 0.01140728),\n",
       "   ('agenda', 0.010882156),\n",
       "   ('sociedad', 0.010255721),\n",
       "   ('año', 0.0089716334),\n",
       "   ('internacional', 0.0078083556),\n",
       "   ('pueblos', 0.0077440306),\n",
       "   ('mayor', 0.0076380875),\n",
       "   ('cuba', 0.0075422772),\n",
       "   ('revisión', 0.0074961474),\n",
       "   ('días', 0.0074536116)]),\n",
       " (1.6192847825586796,\n",
       "  69,\n",
       "  [('sexual', 0.013520168),\n",
       "   ('foro', 0.012319197),\n",
       "   ('naciones', 0.011851257),\n",
       "   ('violencia', 0.011084222),\n",
       "   ('especial', 0.010684384),\n",
       "   ('mujer', 0.0095238648),\n",
       "   ('unidas', 0.0093104569),\n",
       "   ('inclusión', 0.0088284062),\n",
       "   ('representante', 0.0086045926),\n",
       "   ('lgbti', 0.0080073243)]),\n",
       " (1.5784847661852837,\n",
       "  75,\n",
       "  [('lgbti', 0.020027302),\n",
       "   ('posible', 0.01200682),\n",
       "   ('incluyente', 0.010916128),\n",
       "   ('omar', 0.010792557),\n",
       "   ('nieto', 0.010245034),\n",
       "   ('sexual', 0.010141096),\n",
       "   ('resultado', 0.010110006),\n",
       "   ('mundo', 0.010048595),\n",
       "   ('diversidad', 0.0091435006),\n",
       "   ('personas', 0.0090956287)])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_best_topics_list[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3.1873839353578641,\n",
       "  1,\n",
       "  [('foro', 0.031710169489529053),\n",
       "   ('mesas', 0.013839864270060094),\n",
       "   ('participantes', 0.01197594584791448),\n",
       "   ('universidad', 0.010153316467709743),\n",
       "   ('sectores', 0.0092518558130842716),\n",
       "   ('actores', 0.0079997492461898571),\n",
       "   ('diferentes', 0.0078906784879175986),\n",
       "   ('movimientos', 0.0075832429399493176),\n",
       "   ('políticos', 0.0072151437980676678),\n",
       "   ('importantes', 0.0072063790910216422)]),\n",
       " (3.1428975955273675,\n",
       "  3,\n",
       "  [('sociedad', 0.010403642591430205),\n",
       "   ('civil', 0.0077161599356565039),\n",
       "   ('integral', 0.0076318415226086173),\n",
       "   ('través', 0.0069911069612856227),\n",
       "   ('social', 0.0061677876697838986),\n",
       "   ('agenda', 0.0061386666866666871),\n",
       "   ('recomendaciones', 0.0061150440848340556),\n",
       "   ('iniciativas', 0.0060643498978363766),\n",
       "   ('medio', 0.0056871701251030964),\n",
       "   ('importantes', 0.0051027157356209737)]),\n",
       " (3.0672081836365859,\n",
       "  2,\n",
       "  [('comunidades', 0.010200322398191238),\n",
       "   ('medidas', 0.0097055154085956431),\n",
       "   ('protección', 0.0094036789465287481),\n",
       "   ('especial', 0.0085143835347820159),\n",
       "   ('rural', 0.0083764812904136357),\n",
       "   ('violencia', 0.0082650891622537172),\n",
       "   ('planes', 0.008246005614400205),\n",
       "   ('integral', 0.0082337362426919032),\n",
       "   ('cuenta', 0.0080853425619761988),\n",
       "   ('sistema', 0.0078543918162983541)]),\n",
       " (2.5613302119740071,\n",
       "  4,\n",
       "  [('pedagogía', 0.016251478575810559),\n",
       "   ('capacidades', 0.013196912989857722),\n",
       "   ('territorios', 0.013160835261401009),\n",
       "   ('oacp', 0.012265468115476784),\n",
       "   ('territorial', 0.0088947741740371799),\n",
       "   ('comunidades', 0.0080729664162510779),\n",
       "   ('convivencia', 0.0077566795106810693),\n",
       "   ('diálogos', 0.0076549470013438821),\n",
       "   ('iniciativa', 0.0067572667889417857),\n",
       "   ('avances', 0.0065044971390347366)]),\n",
       " (2.0751976879411909,\n",
       "  16,\n",
       "  [('comisión', 0.01123260812046642),\n",
       "   ('internacional', 0.010115609906187444),\n",
       "   ('diferencias', 0.0094352922846567405),\n",
       "   ('pueblos', 0.0093377499161553454),\n",
       "   ('medios', 0.0084154053135915476),\n",
       "   ('comunidades', 0.0069152782170748403),\n",
       "   ('identificar', 0.0068075635674371658),\n",
       "   ('social', 0.0063531855974748265),\n",
       "   ('tierra', 0.0058413432017003627),\n",
       "   ('posturas', 0.0055745362671977021)]),\n",
       " (1.9864783462027722,\n",
       "  5,\n",
       "  [('hecho', 0.0092747663430609358),\n",
       "   ('resolución', 0.0073210386982151023),\n",
       "   ('unidas', 0.0064154266066703321),\n",
       "   ('procesos', 0.0059634227403568508),\n",
       "   ('refrendación', 0.005824354977638193),\n",
       "   ('justa', 0.005819460297216421),\n",
       "   ('total', 0.0057251870777830366),\n",
       "   ('asegurar', 0.0055504957940618457),\n",
       "   ('seguridad', 0.0053822897945506685),\n",
       "   ('centro', 0.0053290623189090787)]),\n",
       " (1.9740122438446777,\n",
       "  11,\n",
       "  [('espacios', 0.0077593596040777951),\n",
       "   ('base', 0.0072425915198524229),\n",
       "   ('papel', 0.0063246507113075105),\n",
       "   ('preparación', 0.0062106902187583539),\n",
       "   ('efectiva', 0.0061674022241578414),\n",
       "   ('diciembre', 0.0061427723875838534),\n",
       "   ('nivel', 0.0056308495083972196),\n",
       "   ('universidad', 0.0054945593599647685),\n",
       "   ('asociación', 0.0054282156918213469),\n",
       "   ('siguientes', 0.0053781691211483591)]),\n",
       " (1.9693571400872538,\n",
       "  25,\n",
       "  [('ámbitos', 0.012201083812437659),\n",
       "   ('grupo', 0.0080578012919896042),\n",
       "   ('aspectos', 0.0077690217010283769),\n",
       "   ('poner', 0.007678360009339932),\n",
       "   ('actividades', 0.0070111006891108224),\n",
       "   ('junio', 0.0061424904054182298),\n",
       "   ('afrocolombianos', 0.0061222225377260053),\n",
       "   ('mecanismos', 0.0059591880373304502),\n",
       "   ('caso', 0.0059262444707646814),\n",
       "   ('realizar', 0.0050677415512950189)]),\n",
       " (1.9484991858053913,\n",
       "  0,\n",
       "  [('foro', 0.026165607881029351),\n",
       "   ('foros', 0.021095834846906327),\n",
       "   ('participantes', 0.014744115441916032),\n",
       "   ('diferentes', 0.0085630822889365254),\n",
       "   ('nacionales', 0.0083266475234313343),\n",
       "   ('actores', 0.0083204254826144373),\n",
       "   ('regionales', 0.007762631535642172),\n",
       "   ('mesas', 0.0069097822985122147),\n",
       "   ('sociales', 0.0067855352104825998),\n",
       "   ('sectores', 0.0066917871560421968)]),\n",
       " (1.9015167775262436,\n",
       "  13,\n",
       "  [('violencia', 0.0090959331682962819),\n",
       "   ('recomendaciones', 0.0075176133977131448),\n",
       "   ('formas', 0.0072691454963931031),\n",
       "   ('especial', 0.0072687149250396602),\n",
       "   ('bolívar', 0.0071458985232388163),\n",
       "   ('fundamentales', 0.0069478022960448036),\n",
       "   ('sexual', 0.0067760840673002027),\n",
       "   ('pueblos', 0.0065704351390082072),\n",
       "   ('institucional', 0.0063698259943022117),\n",
       "   ('transformaciones', 0.0061982685243583283)])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdp_best_topics_list[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
